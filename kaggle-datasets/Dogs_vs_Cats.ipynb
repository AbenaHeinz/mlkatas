{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/bpesquet/machine-learning-katas/blob/master/kaggle-datasets/Dogs_vs_Cats.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_FgsAM08gfr3"
   },
   "source": [
    "# Kata: Dogs vs. Cats\n",
    "\n",
    "Inspired by [this activity](https://developers.google.com/machine-learning/practica/image-classification/).\n",
    "\n",
    "| Learning type | Activity type | Objective |\n",
    "| - | - | - |\n",
    "| Supervised | Multiclass classification | Distinguish between cats and dogs |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PmhLySK7gfsA"
   },
   "source": [
    "## Usage\n",
    "\n",
    "This is a self-correcting exercise generated by [nbgrader](https://github.com/jupyter/nbgrader). \n",
    "\n",
    "Complete the cells beginning with `# YOUR CODE HERE` and run the subsequent cells to check your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qCGcAFTSgfsH"
   },
   "source": [
    "## About the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GMxVpYwsgfsQ"
   },
   "source": [
    "The 2,000 images used in this exercise are excerpted from the [Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats/) dataset available on Kaggle, which contains 25,000 images. Here, we use a subset of the full dataset to decrease training time for educational purposes.\n",
    "\n",
    "![Woof Meow](images/woof_meow.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g5CwRO1mgfsT"
   },
   "source": [
    "## Package setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CHq42ik2gfsY",
    "outputId": "95406787-1f75-4a7d-9ae6-f7a2fcf6333f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img, load_img\n",
    "from keras import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Input, Dropout\n",
    "from keras.applications import VGG16\n",
    "\n",
    "# Display plots inline, change default figure size and change plot resolution to retina\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 8)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# Set Seaborn aesthetic parameters to defaults\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AV6bQixggfsk"
   },
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "d7G36KCWgfsq",
    "nbgrader": {
     "checksum": "05ab214144d072acd34e7ba98790c1a7",
     "grade": false,
     "grade_id": "cell-5d15e9048a1021a6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss_acc(history):\n",
    "    \"\"\"Plot training and (optionally) validation loss and accuracy\"\"\"\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(epochs, loss, '.--', label='Training loss')\n",
    "    final_loss = loss[-1]\n",
    "    title = 'Training loss: {:.4f}'.format(final_loss)\n",
    "    plt.ylabel('Loss')\n",
    "    if 'val_loss' in history.history:\n",
    "        val_loss = history.history['val_loss']\n",
    "        plt.plot(epochs, val_loss, 'o-', label='Validation loss')\n",
    "        final_val_loss = val_loss[-1]\n",
    "        title += ', Validation loss: {:.4f}'.format(final_val_loss)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "\n",
    "    acc = history.history['acc']\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(epochs, acc, '.--', label='Training acc')\n",
    "    final_acc = acc[-1]\n",
    "    title = 'Training accuracy: {:.2f}%'.format(final_acc * 100)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    if 'val_acc' in history.history:\n",
    "        val_acc = history.history['val_acc']\n",
    "        plt.plot(epochs, val_acc, 'o-', label='Validation acc')\n",
    "        final_val_acc = val_acc[-1]\n",
    "        title += ', Validation accuracy: {:.2f}%'.format(final_val_acc * 100)\n",
    "    plt.title(title)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m1q42XrNgfsy"
   },
   "source": [
    "## Step 1: Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "owpXx9IVgfs1",
    "outputId": "31097f26-a8a9-4a0d-fa8a-2d06d890f29c"
   },
   "outputs": [],
   "source": [
    "# Downloading our example data, a .zip of 2,000 JPG pictures, and extracting it locally in `/tmp`\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
    "    -O /tmp/cats_and_dogs_filtered.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p4j4t6L0gftH"
   },
   "outputs": [],
   "source": [
    "# Extracting zip file to the base directory `/tmp/cats_and_dogs_filtered`\n",
    "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()\n",
    "\n",
    "base_dir = '/tmp/cats_and_dogs_filtered'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Directory with our training cat pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "\n",
    "# Directory with our training dog pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Directory with our validation cat pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "\n",
    "# Directory with our validation dog pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sw8xQ2fYgftQ"
   },
   "source": [
    "## Step 2: Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "XAWtGmYagftT",
    "outputId": "fce56f77-6507-4245-b565-a4c4b340b52e"
   },
   "outputs": [],
   "source": [
    "print(f'total training cat images: {len(os.listdir(train_cats_dir))}')\n",
    "print(f'total training dog images: {len(os.listdir(train_dogs_dir))}')\n",
    "print(f'total validation cat images: {len(os.listdir(validation_cats_dir))}')\n",
    "print(f'total validation dog images: {len(os.listdir(validation_dogs_dir))}')\n",
    "\n",
    "# Display some images files for cats and dogs\n",
    "train_cat_fnames = os.listdir(train_cats_dir)\n",
    "print(train_cat_fnames[:10])\n",
    "train_dog_fnames = os.listdir(train_dogs_dir)\n",
    "train_dog_fnames.sort()\n",
    "print(train_dog_fnames[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 921
    },
    "colab_type": "code",
    "deletable": false,
    "editable": false,
    "id": "r31VassNgftg",
    "nbgrader": {
     "checksum": "35202c5191a6ad5a174a3fc53d5ecb83",
     "grade": false,
     "grade_id": "cell-ada83f42e4764374",
     "locked": true,
     "schema_version": 1,
     "solution": false
    },
    "outputId": "ecb0da31-b807-4193-840a-8b9b35fc033b"
   },
   "outputs": [],
   "source": [
    "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "# Index for iterating over images\n",
    "pic_index = 0\n",
    "\n",
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols * 4, nrows * 4)\n",
    "\n",
    "pic_index += 8\n",
    "next_cat_pix = [os.path.join(train_cats_dir, fname) \n",
    "                for fname in train_cat_fnames[pic_index-8:pic_index]]\n",
    "next_dog_pix = [os.path.join(train_dogs_dir, fname) \n",
    "                for fname in train_dog_fnames[pic_index-8:pic_index]]\n",
    "\n",
    "for i, img_path in enumerate(next_cat_pix+next_dog_pix):\n",
    "  # Set up subplot; subplot indices start at 1\n",
    "  sp = plt.subplot(nrows, ncols, i + 1)\n",
    "  sp.axis('Off') # Don't show axes (or gridlines)\n",
    "\n",
    "  img = mpimg.imread(img_path)\n",
    "  plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-du_wFTNgfty"
   },
   "source": [
    "## Step 3 : training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "cE3HXWm_gfuC",
    "outputId": "f738b5a8-d4b1-4e1b-9377-2195c2140275"
   },
   "outputs": [],
   "source": [
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Create a CNN model able to be trained on 150x150x3 images. Show its summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "colab_type": "code",
    "deletable": false,
    "id": "pUry332xgft1",
    "nbgrader": {
     "checksum": "fd95b9eb24d0726e95461f92dfc96ba3",
     "grade": false,
     "grade_id": "cell-04d69d810f92ac12",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "outputId": "2e85b6ab-2e71-439c-bf7c-1bf1775dfc5b"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Compile and train your model to reach a validation accuracy > 70%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "colab_type": "code",
    "id": "C1RULCYIgfuL",
    "outputId": "c1a7e3b2-045e-4148-c3e7-6a4b69f08d03"
   },
   "outputs": [],
   "source": [
    "# Compile and train the model\n",
    "\n",
    "model.compile('adam',\n",
    "              'binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,  # 2000 images = batch_size * steps\n",
    "      epochs=15,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,  # 1000 images = batch_size * steps\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620
    },
    "colab_type": "code",
    "id": "P-CSXqGGgfuX",
    "outputId": "0934242d-fc4b-4fac-b42e-8bdb8ab0b9ad"
   },
   "outputs": [],
   "source": [
    "plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fd01474463655f7734f340a831f1546f",
     "grade": true,
     "grade_id": "cell-25e0efece6159ffe",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve final validation accuracy\n",
    "val_acc = history.history['val_acc'][-1]\n",
    "# Assert final accuracy\n",
    "assert_true(val_acc > 0.70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4d5jVYLMgful"
   },
   "source": [
    "## Step 4: Preventing overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H31PYAIGgfun"
   },
   "source": [
    "### Adding data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1272
    },
    "colab_type": "code",
    "id": "4nWSr6wtgfup",
    "outputId": "4345d89d-bf74-434c-faf9-048233b05648"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "img_path = os.path.join(train_cats_dir, train_cat_fnames[2])\n",
    "img = load_img(img_path, target_size=(150, 150))  # this is a PIL image\n",
    "x = img_to_array(img)  # Numpy array with shape (150, 150, 3)\n",
    "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
    "\n",
    "# The .flow() command below generates batches of randomly transformed images\n",
    "# It will loop indefinitely, so we need to `break` the loop at some point!\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1):\n",
    "  plt.figure(i, figsize=(4, 4))\n",
    "  imgplot = plt.imshow(array_to_img(batch[0]))\n",
    "  i += 1\n",
    "  if i % 5 == 0:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "EMerY3R4gfu1",
    "outputId": "9d95ccc8-627b-4721-9e98-da2b7bc313ea"
   },
   "outputs": [],
   "source": [
    "# Adding rescale, rotation_range, width_shift_range, height_shift_range,\n",
    "# shear_range, zoom_range, and horizontal flip to our ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 32 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 32 using test_datagen generator\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "scUn7GmPgfvG"
   },
   "source": [
    "### Adding Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Create a new model with a `Dropout` layer to your model just before the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "colab_type": "code",
    "deletable": false,
    "id": "KZ1J1BOXgfvN",
    "nbgrader": {
     "checksum": "5c50e1c7ef3d06d134f731712c58304f",
     "grade": false,
     "grade_id": "cell-390ad992447c2c7a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "outputId": "4ef6a99a-7e3e-4cf1-c556-9b4fcc574a87"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Compile and train your model to reach a validation accuracy > 73%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1059
    },
    "colab_type": "code",
    "id": "AE5Vwnj8gfvb",
    "outputId": "fb0af83b-eba4-432b-a42b-39a1268e091e"
   },
   "outputs": [],
   "source": [
    "# Compile and train the model\n",
    "\n",
    "model.compile('adam',\n",
    "              'binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,  # 2000 images = batch_size * steps\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,  # 1000 images = batch_size * steps\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620
    },
    "colab_type": "code",
    "id": "kIJoNYGKgfvx",
    "outputId": "be734e60-c26e-46a3-febf-d813a224320e"
   },
   "outputs": [],
   "source": [
    "plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "453e6c9c2a5054a46816d25b582f003b",
     "grade": true,
     "grade_id": "cell-bcb916e09d40961d",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve final validation accuracy\n",
    "val_acc = history.history['val_acc'][-1]\n",
    "# Assert final accuracy\n",
    "assert_true(val_acc > 0.73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9inqQHz8gfwE"
   },
   "source": [
    "## Step 5: Using a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "colab_type": "code",
    "id": "Njy8rDp8gfwF",
    "outputId": "db602d8d-b484-4ca3-9068-b92d27d06e16"
   },
   "outputs": [],
   "source": [
    "# Using the convolutional base of VGG16\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150, 150, 3))\n",
    "\n",
    "# Freezing the convolutional base\n",
    "# This prevents weight updates during training\n",
    "conv_base.trainable = False\n",
    "\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Create a Dense classifier on top of the convolutional base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "deletable": false,
    "id": "eYkRlL3GgfwL",
    "nbgrader": {
     "checksum": "f96c02d6914ce78580d3e2fc3ee907a1",
     "grade": false,
     "grade_id": "cell-bca3e5435516b27d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "outputId": "ea535cb5-b3fc-4716-dfd0-4dadcdbb5567"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Compile and train your model to reach a validation accuracy > 87%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "colab_type": "code",
    "id": "zDSvHoBRgfwT",
    "outputId": "86cd5e3b-4d97-49a3-be25-ce2c5334e71c"
   },
   "outputs": [],
   "source": [
    "# Compile and train the model\n",
    "\n",
    "model.compile('adam',\n",
    "              'binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,  # 2000 images = batch_size * steps\n",
    "      epochs=15,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,  # 1000 images = batch_size * steps\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620
    },
    "colab_type": "code",
    "id": "bQO02DuTlcOv",
    "outputId": "6d8857a7-7500-4535-bc4e-04da4c1a1399"
   },
   "outputs": [],
   "source": [
    "plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "adae36f25cbec121e5279ce3edfcb14e",
     "grade": true,
     "grade_id": "cell-30da406841021461",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve final validation accuracy\n",
    "val_acc = history.history['val_acc'][-1]\n",
    "# Assert final accuracy\n",
    "assert_true(val_acc > 0.87"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5LUQnpI-gfwY"
   },
   "source": [
    "## TODO\n",
    "\n",
    "- Show images dimension\n",
    "- Visualizing intermediate layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Dogs_vs_Cats(1).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
